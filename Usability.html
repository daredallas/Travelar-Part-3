<!DOCTYPE html>
<html>
<head>

<title>Travelar, your new virtual travel companion</title>
  <!-- lol I'm a comment also this is external stuff -->

<link rel="stylesheet" type="text/css" href="css/styles.css">


</head>

<body>

<div class="centered_content">

<h1>Travel<span class="other-color">ar</span></h1>
<div id="signature">by Human Pals</div>

			<a href="index.html" target="_self">Prototype</a> | 
			<a href="Report.html" target="_self">Tools</a> |
			<a href="Goals.html" target="_self">Goals</a> |
			<a href="User-experience.html" target="_self">User experience</a> |
			<a href="Usability.html" target="_self">Usability</a> |
			<a href="User-requirements.html" target="_self">User requirements</a> |
			<a href="Group-Member.html" target="_self">Group Members</a>

<h2>Usability Goals</h2>		

<p>
<i>Able to provide specific user interfaces for different situations (keyboard, star rating, directions):</i>
<br><br>
The prototype does not fully implement all of the user interfaces required by the full app as Marvel App is limited in this way. We believe for the purpose of evaluating the prototype, a user would understand how interfaces such as a keyboard would have been required to enter the information for logging in. The specific interfaces we are able to simulate were a directions screen and inputting stars for a rating. 
<br><br>
<i>Controls can be used in both landscape and portrait orientation: </i>
<br><br>
The application is intended to work in both landscape and portrait mode. Due to time constraints, the prototype does not currently support landscape orientation as it would require reformatting all of our portrait view screens. 
<br><br>

<i>Able to preload nearby location data when the app is opened. Relevant information is retrieved quickly:</i>
<br><br>
The prototype displays locations with distance associated to them. The functionality to preload nearby locations was not added to the prototype for technical reasons as the prototyping tool does not support it. The prototype does however show how the list would be displayed. Performance is determined by the backend processing and could not be demonstrated in the prototype, but would be considered in a full implementation.
<br><br>
<i>Able to collect user information anonymously to improve services:</i>
<br><br>
The current prototype does not currently support data analysis as it is mainly a visual high fidelity prototype. For actual usage, analytics would be used to determine popular locations to optimize what gets cached at certain locations where popular attractions are.
<br><br>

<i>Quick startup for the app:</i>
<br><br>
As the prototype is intended to demonstrate the process of logging in, the feature of remembering a users log in for quick startup to the main AR view is not implemented in the prototype. In the full application, the login screen would not be required every time it is opened. Therefore, the startup of the app would be quick after all the assets have loaded in and that depends on each device and any optimizations made for those devices.
<br><br>

<i>Able to leave reviews quickly:</i>
<br><br>
Rating a location takes less than 30 seconds. and the time it takes to type in a comment: once the user points on the location there’s at most 3 clearly visible buttons (“name of location” -> “more” -> “review”) they have to press to leave a review. The user can also take the following path: “name” -> “review stars”, the stars serve as a hidden button that takes the user directly to the review screen. It is reasonable to expect that the user will take one of those routes and see the review menu after a few seconds. The “post” button is clearly visible and only completes the review after text and stars have been included in the review.
<br><br>

<i>Minimal learning curve:</i>
<br><br>
The application starts out, after a user signs in or creates an account, with a text bubble prompt that tells the user that pointing at a desired location is the primary function of the application. By doing this, those that are misguided can easily tell what to do by reading as the prompt only disappears after the image recognition has worked at least once. After the first use, the application can be correlated to looking as what the user sees is what they are getting. The user can easily remember how to perform a task after having performed it once as all actions take at most 4 taps and all buttons are clearly and consistently labeled.
<br><br>
<i>The app should not allow the user to get lost in their surroundings:</i>
<br><br>
One important aspect of the application is that the AR view is not obstructed by buttons that are too large so the user can clearly see what’s on the screen and what a label refers to. In the application that we implemented, the labels for locations only load in when the camera has been pointed at them for a certain amount of time. With this implementation, there is a delay on the label showing up which potentially causes a little bit of frustration but also removes constant pop-up while scrolling through a scene. As a result, users can still be focused on what they are looking for. In addition different locations are colour coded differently so the user can tell that they are different.
</p>

</div>
</div>

<script src="js/script.js"></script>


</body>

</html>
